{"version":3,"file":"static/js/62.c2d00140.chunk.js","mappings":"kKAAe,SAASA,IACpB,OACIC,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CAACC,QAAQ,OAAQC,cAAc,UAAUC,SAAA,EACjDC,EAAAA,EAAAA,KAAA,KAAAD,SAAG,sQAIHC,EAAAA,EAAAA,KAAA,KAAAD,SAAG,yJAGHC,EAAAA,EAAAA,KAAA,MAAIJ,MAAO,CAACK,YAAY,OAAQC,UAAW,UAAUH,SAAC,wBACtDC,EAAAA,EAAAA,KAAA,OAAKJ,MAAO,CAACC,QAAS,OAAQM,eAAgB,eAAgBC,aAAa,QAAQL,UAC/EC,EAAAA,EAAAA,KAAA,OAAKK,IAAKC,EAAQ,KAAmCC,IAAI,0BAA0BX,MAAO,CAACY,SAAS,cAExGR,EAAAA,EAAAA,KAAA,KAAAD,SAAG,udAKHC,EAAAA,EAAAA,KAAA,MAAIJ,MAAO,CAACK,YAAY,OAAQC,UAAW,UAAUH,SAAC,4BACtDC,EAAAA,EAAAA,KAAA,OAAKJ,MAAO,CAACC,QAAS,OAAQM,eAAgB,eAAgBC,aAAa,QAAQL,UAC/EC,EAAAA,EAAAA,KAAA,OAAKK,IAAKC,EAAQ,KAA+BC,IAAI,qCAAqCX,MAAO,CAACY,SAAS,cAE/GR,EAAAA,EAAAA,KAAA,KAAAD,SAAG,qPAMf,C","sources":["Projects/Synesthize.js"],"sourcesContent":["export default function Synesthize() {\r\n    return (\r\n        <div style={{display:\"flex\", flexDirection:\"column\"}}>\r\n            <p> \r\n                This app is an experimental interpretation of sound into color. The app takes the user's microphone input, \r\n                then detects any musical notes being played to convert them into specific colors. This was made in my senior year at UCF with a team of five members.\r\n            </p>\r\n            <p> \r\n                There was both a desktop app and web app created for this project. The app was a built with a MERN stack and built as a desktop app using Electron.\r\n            </p>\r\n            <h3 style={{marginBlock:\"30px\", alignSelf: \"center\"}}>Synesthize Website</h3>\r\n            <div style={{display: \"flex\", justifyContent: \"space-around\", marginBottom:\"30px\"}}>\r\n                <img src={require(\"./Images/SynesthizeWebsite.png\")} alt=\"The Synesthize web app.\" style={{maxWidth:\"800px\"}}/>\r\n            </div>\r\n            <p>\r\n                My role in the project was mostly constructing the methods used to determine the notes played in the microphone input. This consisted of taking the sound data\r\n                and performing a signal processing technique known as the Fourier Transform. A Fourier Transform deconstructs a signal into it's base frequencies. This is visualized in the form of spikes in data.\r\n                This allows the app to find prominent frequencies which could then be identified as particular musical notes.\r\n            </p>\r\n            <h3 style={{marginBlock:\"30px\", alignSelf: \"center\"}}>Fourier Transform data</h3>\r\n            <div style={{display: \"flex\", justifyContent: \"space-around\", marginBottom:\"30px\"}}>\r\n                <img src={require(\"./Images/TransformData.png\")} alt=\"Example of Fourier Transform data.\" style={{maxWidth:\"800px\"}}/>\r\n            </div>\r\n            <p>\r\n                I was able to learn a lot about signal processing in this project. I think this was an interesting problem to solve. I may revisit this app in the future to improve\r\n                the frontend and further explore the concept of turning sound into color.\r\n            </p>\r\n        </div>\r\n    );\r\n}"],"names":["Synesthize","_jsxs","style","display","flexDirection","children","_jsx","marginBlock","alignSelf","justifyContent","marginBottom","src","require","alt","maxWidth"],"sourceRoot":""}